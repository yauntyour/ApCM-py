# train_pca_baseline.py
from io import BytesIO
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import zipfile
from sklearn.decomposition import PCA
import sys
import logging
from datetime import datetime, timezone

# é…ç½®æ—¥å¿—ï¼ˆå®Œå…¨ä»¿ç…§ vis.pyï¼‰
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    handlers=[
        logging.FileHandler(
            f"log/pca_{datetime.now(timezone.utc).strftime('%Y-%m-%d_%H-%M-%S_UTC')}.log",
            encoding="utf-8",
        ),
        logging.StreamHandler(sys.stdout),
    ],
)


def set_seed(seed=42):
    import random

    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)


def load_data(filepath):
    """åŠ è½½çœŸå®æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    images = []
    with zipfile.ZipFile(filepath, "r") as zip_ref:
        file_list = zip_ref.namelist()
        for file_name in file_list:
            if "png" in file_name:
                img = Image.open(BytesIO(zip_ref.read(file_name)))
                img = img.convert("L")
                img_tensor = torch.tensor(np.array(img), dtype=torch.float32)
                images.append(img_tensor)
    return images


def generate_training_images(n=1000, size=(32, 32)):
    """ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ï¼ˆä¸ vis.py å®Œå…¨ä¸€è‡´ï¼‰"""
    images = []
    for _ in range(n):
        img = torch.zeros(size)
        num_blobs = torch.randint(3, 9, (1,)).item()
        for _ in range(num_blobs):
            cx = torch.randint(5, size[0] - 5, (1,)).item()
            cy = torch.randint(5, size[1] - 5, (1,)).item()
            x, y = torch.meshgrid(torch.arange(size[0]), torch.arange(size[1]))
            d2 = (x - cx) ** 2 + (y - cy) ** 2
            sigma = torch.randint(2, 5, (1,)).item()
            blob = torch.exp(-d2 / (2 * sigma**2))
            img += blob * torch.rand(1) * 0.8
        img += torch.randn_like(img) * 0.05
        img = torch.clamp(img, 0, 1)
        images.append(img)
    return images


def preprocess_images(images, target_size=(32, 32), is_flat=False):
    """é¢„å¤„ç†å›¾åƒï¼ˆä¸ vis.py å®Œå…¨ä¸€è‡´ï¼‰"""
    processed_images = []
    for img in images:
        if is_flat:
            img_2d = img.view(target_size)
            img_pil = Image.fromarray((img_2d.numpy() * 255).astype(np.uint8), mode="L")
        else:
            img_pil = Image.fromarray((img.numpy() * 255).astype(np.uint8), mode="L")
        if img_pil.size != target_size:
            img_resized = img_pil.resize(target_size)
        else:
            img_resized = img_pil
        img_tensor = torch.tensor(np.array(img_resized), dtype=torch.float32)
        img_normalized = img_tensor / 255.0
        img_flat = img_normalized.view(-1)
        processed_images.append(img_flat)
    return torch.stack(processed_images)


def psnr(original, reconstructed):
    """è®¡ç®—å³°å€¼ä¿¡å™ªæ¯”ï¼ˆä¸ vis.py å®Œå…¨ä¸€è‡´ï¼‰"""
    mse = F.mse_loss(original, reconstructed)
    if mse == 0:
        return float("inf")
    max_val = 1.0
    psnr_val = 20 * torch.log10(max_val / torch.sqrt(mse))
    return psnr_val


def visualize_comparison(
    originals,
    reconstructions,
    titles=["Original", "Reconstructed"],
    num_samples=4,
    save_path=None,
):
    """å¯è§†åŒ–å¯¹æ¯”ï¼ˆä¸ vis.py å®Œå…¨ä¸€è‡´ï¼‰"""
    fig, axes = plt.subplots(2, num_samples, figsize=(12, 6))
    for i in range(min(num_samples, len(originals))):
        orig_img = originals[i].view(32, 32).detach().cpu().numpy()
        recon_img = reconstructions[i].view(32, 32).detach().cpu().numpy()
        axes[0, i].imshow(orig_img, cmap="gray")
        axes[0, i].set_title(f"{titles[0]} {i+1}")
        axes[0, i].axis("off")
        axes[1, i].imshow(recon_img, cmap="gray")
        axes[1, i].set_title(f"{titles[1]} {i+1}")
        axes[1, i].axis("off")
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        logging.info(f"Visualization saved to {save_path}")
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    set_seed(42)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logging.info(f"Using device: {device}")
    logging.info("=" * 60)
    logging.info("ğŸ¯ Baseline: PCA Compression vs IDRP (for comparison)")
    logging.info("=" * 60)

    # ==================== ç”Ÿæˆè®­ç»ƒæ•°æ® ====================
    logging.info("\nğŸ”§ ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    train_images = generate_training_images(n=2000, size=(32, 32))
    logging.info(f"ç”Ÿæˆäº† {len(train_images)} å¼ è®­ç»ƒå›¾åƒ")

    # é¢„å¤„ç†è®­ç»ƒæ•°æ®ï¼ˆæ‰å¹³åŒ–ï¼‰
    train_data_flat = preprocess_images(
        train_images, target_size=(32, 32), is_flat=False
    )
    logging.info(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_data_flat.shape}")  # (2000, 1024)

    # ==================== åŠ è½½çœŸå®æµ‹è¯•æ•°æ® ====================
    logging.info("\nğŸ“‚ åŠ è½½çœŸå®æµ‹è¯•æ•°æ®...")
    try:
        test_images_raw = load_data("dataset/row_roket.zip")
        logging.info(f"åŠ è½½äº† {len(test_images_raw)} å¼ çœŸå®æµ‹è¯•å›¾åƒ")
    except FileNotFoundError:
        logging.error("âŒ é”™è¯¯: æœªæ‰¾åˆ° dataset/row_roket.zip æ–‡ä»¶")
        exit(1)

    test_data_flat = preprocess_images(
        test_images_raw, target_size=(32, 32), is_flat=False
    )
    logging.info(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data_flat.shape}")

    # ==================== å‚æ•°è®¾ç½® ====================
    input_dim = train_data_flat.shape[1]  # 1024
    m_dim = 128
    compression_ratio = m_dim / input_dim
    logging.info(f"\nğŸ“Š PCA å‚æ•°:")
    logging.info(f" è¾“å…¥ç»´åº¦: {input_dim}")
    logging.info(f" å‹ç¼©ç»´åº¦: {m_dim}")
    logging.info(f" å‹ç¼©ç‡: {compression_ratio:.3f} ({input_dim//m_dim}:1)")

    # ==================== è®­ç»ƒ PCAï¼ˆæ‹Ÿåˆï¼‰ ====================
    logging.info("\nğŸš€ æ‹Ÿåˆ PCA æ¨¡å‹ï¼ˆåœ¨ç”Ÿæˆæ•°æ®ä¸Šï¼‰...")
    pca = PCA(n_components=m_dim, svd_solver="full", random_state=42)

    # å°†è®­ç»ƒæ•°æ®è½¬ä¸º NumPy å¹¶æ ‡å‡†åŒ–ï¼ˆå¯é€‰ï¼Œä½†é€šå¸¸ PCA å¯¹ scale æ•æ„Ÿï¼‰
    X_train_np = train_data_flat.cpu().numpy()
    # æ³¨æ„ï¼šè¿™é‡Œä¸å½’ä¸€åŒ–å‡å€¼ï¼Œå› ä¸ºå›¾åƒå·²å½’ä¸€åŒ–åˆ° [0,1]
    pca.fit(X_train_np)
    logging.info(
        f"PCA æ‹Ÿåˆå®Œæˆã€‚è§£é‡Šæ–¹å·®æ¯”ä¾‹: {pca.explained_variance_ratio_.sum():.4f}"
    )

    # ==================== æµ‹è¯•é˜¶æ®µ ====================
    logging.info("\n" + "=" * 60)
    logging.info("ğŸ§ª å¼€å§‹æµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰...")
    logging.info("=" * 60)

    X_test_np = test_data_flat.cpu().numpy()
    logging.info(f"æµ‹è¯•æ•°æ®ç»´åº¦: {X_test_np.shape}")

    # å‹ç¼©
    z_comp = pca.transform(X_test_np)  # (N, m_dim)
    logging.info(f"å‹ç¼©åç»´åº¦: {z_comp.shape}")
    logging.info(f"å‹ç¼©ç‡: {z_comp.shape[1] / X_test_np.shape[1]:.3f}")

    # è§£å‹ï¼ˆé‡å»ºï¼‰
    X_recon_np = pca.inverse_transform(z_comp)  # (N, 1024)
    X_recon = torch.from_numpy(X_recon_np).float().to(device)
    test_data_device = test_data_flat.to(device)

    # è¯„ä¼°
    mae = F.l1_loss(test_data_device, X_recon).item()
    mse = F.mse_loss(test_data_device, X_recon).item()
    psnr_val = psnr(test_data_device, X_recon).item()

    logging.info(f"\nğŸ“Š PCA æµ‹è¯•ç»“æœ:")
    logging.info(f" é‡å»º MAE: {mae:.6f}")
    logging.info(f" é‡å»º MSE: {mse:.6f}")
    logging.info(f" PSNR: {psnr_val:.2f} dB")

    # å¯è§†åŒ–å¯¹æ¯”
    logging.info("\nğŸ“¸ ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾ï¼ˆçœŸå®æ•°æ® vs PCA é‡å»ºï¼‰...")
    visualize_comparison(
        test_data_device[:4],
        X_recon[:4],
        titles=[
            f"Real Image {compression_ratio:.3f}",
            f"PCA Reconstructed {compression_ratio:.3f}",
        ],
        num_samples=min(4, len(test_data_device)),
        save_path=f"assets/PCA_Example_{input_dim//m_dim}to1.png",
    )

    # æ¯å¼ å›¾åƒçš„è¯¦ç»†æŒ‡æ ‡
    logging.info("\nğŸ“ˆ æ¯å¼ æµ‹è¯•å›¾åƒçš„è¯¦ç»†æŒ‡æ ‡:")
    for i in range(min(5, len(test_data_device))):
        psnr_single = psnr(test_data_device[i], X_recon[i]).item()
        mae_single = F.l1_loss(test_data_device[i], X_recon[i]).item()
        mse_single = F.mse_loss(test_data_device[i], X_recon[i]).item()
        logging.info(
            f" å›¾åƒ {i+1}: PSNR = {psnr_single:.2f} dB, MAE = {mae_single:.6f}, MSE = {mse_single:.6f}"
        )

    logging.info("\n" + "=" * 60)
    logging.info("âœ… PCA åŸºçº¿æµ‹è¯•å®Œæˆï¼")
    logging.info(f" è®­ç»ƒæ•°æ®: {len(train_data_flat)} å¼ ç”Ÿæˆå›¾åƒ")
    logging.info(f" æµ‹è¯•æ•°æ®: {len(test_data_flat)} å¼ çœŸå®å›¾åƒ")
    logging.info(f" å‹ç¼©æ•ˆæœ: {input_dim} ç»´ â†’ {m_dim} ç»´")
    logging.info("=" * 60)
