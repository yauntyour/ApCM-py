from io import BytesIO
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import zipfile
from net import ApCM
import sys
import logging
from datetime import datetime, timezone

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    handlers=[
        logging.FileHandler(
            f"log/{datetime.now(timezone.utc).strftime("%Y-%m-%d_%H-%M-%S_UTC")}.log",
            encoding="utf-8",
        ),
        logging.StreamHandler(sys.stdout),  # åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯
    ],
)


def set_seed(seed=42):
    import random
    import numpy as np

    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)


def load_data(filepath):
    """
    åŠ è½½çœŸå®æ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    """
    images = []
    with zipfile.ZipFile(filepath, "r") as zip_ref:
        file_list = zip_ref.namelist()
        for file_name in file_list:
            if "png" in file_name:
                # è¯»å–å›¾åƒ
                img = Image.open(BytesIO(zip_ref.read(file_name)))
                img = img.convert("L")
                img_tensor = torch.tensor(np.array(img), dtype=torch.float32)
                images.append(img_tensor)
    return images


def generate_training_images(n=1000, size=(32, 32)):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    """
    images = []
    for _ in range(n):
        # åˆ›å»ºå¸¦ç»“æ„çš„æ¨¡æ‹Ÿå›¾åƒï¼ˆæ¨¡æ‹ŸçœŸå®å›¾åƒçš„å±€éƒ¨ç›¸å…³æ€§ï¼‰
        img = torch.zeros(size)
        # éšæœºæ·»åŠ 3-8ä¸ªé«˜æ–¯blobï¼Œæ¨¡æ‹ŸçœŸå®å›¾åƒç‰¹å¾
        num_blobs = torch.randint(3, 9, (1,)).item()
        for _ in range(num_blobs):
            cx = torch.randint(5, size[0] - 5, (1,)).item()
            cy = torch.randint(5, size[1] - 5, (1,)).item()
            x, y = torch.meshgrid(torch.arange(size[0]), torch.arange(size[1]))
            d2 = (x - cx) ** 2 + (y - cy) ** 2
            sigma = torch.randint(2, 5, (1,)).item()  # éšæœºæ ‡å‡†å·®
            blob = torch.exp(-d2 / (2 * sigma**2))
            img += blob * torch.rand(1) * 0.8  # éšæœºå¼ºåº¦
        # æ·»åŠ ä¸€äº›éšæœºå™ªå£°
        img += torch.randn_like(img) * 0.05
        img = torch.clamp(img, 0, 1)
        images.append(img)
    return images


def preprocess_images(images, target_size=(32, 32), is_flat=False):
    """
    é¢„å¤„ç†å›¾åƒï¼šè°ƒæ•´å¤§å°ã€å±•å¹³ã€å½’ä¸€åŒ–

    Args:
        images: å›¾åƒåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯2Då¼ é‡æˆ–å±•å¹³çš„å¼ é‡
        target_size: ç›®æ ‡å°ºå¯¸
        is_flat: è¾“å…¥å›¾åƒæ˜¯å¦å·²ç»å±•å¹³
    """
    processed_images = []
    for img in images:
        if is_flat:
            # å¦‚æœå·²ç»æ˜¯å±•å¹³çš„ï¼Œé‡å¡‘ä¸ºå›¾åƒæ ¼å¼
            img_2d = img.view(target_size)
            img_pil = Image.fromarray((img_2d.numpy() * 255).astype(np.uint8), mode="L")
        else:
            # å¦‚æœæ˜¯2Då›¾åƒï¼Œè½¬æ¢ä¸ºPILæ ¼å¼
            img_pil = Image.fromarray((img.numpy() * 255).astype(np.uint8), mode="L")

        # è°ƒæ•´å¤§å°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if img_pil.size != target_size:
            img_resized = img_pil.resize(target_size)
        else:
            img_resized = img_pil

        img_tensor = torch.tensor(np.array(img_resized), dtype=torch.float32)

        # å½’ä¸€åŒ–åˆ° [0, 1]
        img_normalized = img_tensor / 255.0

        # å±•å¹³
        img_flat = img_normalized.view(-1)
        processed_images.append(img_flat)

    return torch.stack(processed_images)


def psnr(original, reconstructed):
    """
    è®¡ç®—å³°å€¼ä¿¡å™ªæ¯”
    """
    mse = F.mse_loss(original, reconstructed)
    if mse == 0:
        return float("inf")
    max_val = 1.0  # å½’ä¸€åŒ–åçš„æœ€å¤§å€¼
    psnr_val = 20 * torch.log10(max_val / torch.sqrt(mse))
    return psnr_val


def visualize_comparison(
    originals,
    reconstructions,
    titles=["Original", "Reconstructed"],
    num_samples=4,
    save_path=None,
):
    """
    å¯è§†åŒ–åŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒçš„å¯¹æ¯”
    """
    fig, axes = plt.subplots(2, num_samples, figsize=(12, 6))

    for i in range(min(num_samples, len(originals))):
        # é‡å¡‘ä¸ºå›¾åƒæ ¼å¼ (32, 32)
        orig_img = originals[i].view(32, 32).detach().cpu().numpy()
        recon_img = reconstructions[i].view(32, 32).detach().cpu().numpy()

        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        axes[0, i].imshow(orig_img, cmap="gray")
        axes[0, i].set_title(f"{titles[0]} {i+1}")
        axes[0, i].axis("off")

        # æ˜¾ç¤ºé‡å»ºå›¾åƒ
        axes[1, i].imshow(recon_img, cmap="gray")
        axes[1, i].set_title(f"{titles[1]} {i+1}")
        axes[1, i].axis("off")

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        logging.info(f"Loss curves saved to {save_path}")

    plt.tight_layout()
    plt.show()


def plot_loss_curves(train_loss_history, train_recon_loss_history, save_path=None):
    """
    ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿

    Args:
        train_loss_history: æ€»æŸå¤±å†å²
        train_recon_loss_history: é‡æ„æŸå¤±å†å²
        save_path: ä¿å­˜å›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    plt.figure(figsize=(12, 5))

    # ç»˜åˆ¶æ€»æŸå¤±
    plt.subplot(1, 2, 1)
    plt.plot(train_loss_history, label="Total Loss", color="blue", linewidth=2)
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Total Loss Curve")
    plt.grid(True, alpha=0.3)
    plt.legend()

    # ç»˜åˆ¶é‡æ„æŸå¤±
    plt.subplot(1, 2, 2)
    plt.plot(
        train_recon_loss_history, label="Reconstruction Loss", color="red", linewidth=2
    )
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Reconstruction Loss Curve")
    plt.grid(True, alpha=0.3)
    plt.legend()

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        logging.info(f"Loss curves saved to {save_path}")

    plt.show()


if __name__ == "__main__":

    save_path = "models/best_model.pth"

    set_seed(42)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logging.info(f"Using device: {device}")

    logging.info("=" * 60)
    logging.info("ğŸ¯ è®­ç»ƒç­–ç•¥ï¼šä½¿ç”¨ç”Ÿæˆæ•°æ®è®­ç»ƒï¼ŒçœŸå®æ•°æ®æµ‹è¯•")
    logging.info("=" * 60)

    # ==================== ç”Ÿæˆè®­ç»ƒæ•°æ® ====================
    logging.info("\nğŸ”§ ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    train_images = generate_training_images(n=2000, size=(32, 32))  # ç”Ÿæˆ2000å¼ è®­ç»ƒå›¾åƒ
    logging.info(f"ç”Ÿæˆäº† {len(train_images)} å¼ è®­ç»ƒå›¾åƒ")

    # é¢„å¤„ç†è®­ç»ƒæ•°æ®
    train_data = preprocess_images(train_images, target_size=(32, 32), is_flat=False)
    logging.info(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_data.shape}")

    # ==================== åŠ è½½çœŸå®æµ‹è¯•æ•°æ® ====================
    logging.info("\nğŸ“‚ åŠ è½½çœŸå®æµ‹è¯•æ•°æ®...")
    try:
        test_images_raw = load_data("dataset/row_roket.zip")
        logging.info(f"åŠ è½½äº† {len(test_images_raw)} å¼ çœŸå®æµ‹è¯•å›¾åƒ")
    except FileNotFoundError:
        logging.info("âŒ é”™è¯¯: æœªæ‰¾åˆ° dataset/row_roket.zip æ–‡ä»¶")
        logging.info("è¯·ç¡®ä¿çœŸå®æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼Œç”¨äºæµ‹è¯•æ¨¡å‹æ€§èƒ½")
        exit(1)

    # é¢„å¤„ç†æµ‹è¯•æ•°æ®
    test_data = preprocess_images(test_images_raw, target_size=(32, 32), is_flat=False)
    logging.info(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")

    # ==================== å‚æ•°è®¾ç½® ====================
    input_dim = train_data.shape[1]  # 32*32 = 1024
    m_dim = 128  # å‹ç¼©ç»´åº¦
    batch_size = 32  # è®­ç»ƒæ‰¹æ¬¡å¤§å°
    epochs = 2000
    lr = 1e-5
    use_lr_scheduler = True

    n_layers = 12
    hidden_dim = m_dim * 6
    aux_predictor_hidden = m_dim * 6

    logging.info(f"\nğŸ“Š å‚æ•°è®¾ç½®:")
    logging.info(f"  è¾“å…¥ç»´åº¦: {input_dim}")
    logging.info(f"  å‹ç¼©ç»´åº¦: {m_dim}")
    logging.info(f"  å‹ç¼©ç‡: {m_dim/input_dim:.3f} ({input_dim//m_dim}:1)")
    logging.info(f"  æ‰¹å¤§å°: {batch_size}")
    logging.info(f"  è®­ç»ƒè½®æ•°: {epochs}")
    logging.info(f"  å­¦ä¹ ç‡: {lr}")
    logging.info(f"  å­¦ä¹ ç‡è°ƒæ•´: {use_lr_scheduler}")
    logging.info(f"  ç½‘ç»œå±‚æ•°: {n_layers}")
    logging.info(f"  éšè—å±‚ç»´åº¦: {hidden_dim}")
    logging.info(f"  é¢„æµ‹å±‚ç»´åº¦: {aux_predictor_hidden}")

    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    model = ApCM(
        L=32,
        D=32,
        m_dim=m_dim,
        max_mem=16,
        n_layers=n_layers,
        hidden_dim=hidden_dim,
        aux_predictor_hidden=aux_predictor_hidden,
    ).to(device)

    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    if use_lr_scheduler:
        try:
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode="min", factor=0.5, patience=50, verbose=True
            )
        except TypeError:
            logging.info("æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬ PyTorchï¼Œä½¿ç”¨æ—  verbose å‚æ•°çš„å­¦ä¹ ç‡è°ƒåº¦å™¨")
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode="min", factor=0.5, patience=50
            )

    def loss_fn(x, x_recon, z_comp, log_det):
        recon_loss = F.mse_loss(x_recon, x)
        prior_loss = 0.5 * torch.mean(z_comp.pow(2))
        total_loss = recon_loss + 0.01 * prior_loss
        return total_loss, recon_loss

    # åˆå§‹åŒ–æŸå¤±è®°å½•
    train_loss_history = []
    train_recon_loss_history = []
    best_loss = float("inf")
    lr_update_counter = 0  # è®°å½•å­¦ä¹ ç‡è°ƒæ•´æ¬¡æ•°

    # ==================== è®­ç»ƒé˜¶æ®µ ====================
    logging.info("\nğŸš€ å¼€å§‹è®­ç»ƒï¼ˆä½¿ç”¨ç”Ÿæˆæ•°æ®ï¼‰...")
    for epoch in range(epochs):
        # éšæœºé‡‡æ ·ä¸€ä¸ªæ‰¹æ¬¡
        indices = torch.randperm(len(train_data))[:batch_size]
        x_batch = train_data[indices].to(device)

        # å‰å‘ä¼ æ’­
        z_comp, z_aux_true, log_det = model.vectorEncoder(x_batch)
        x_recon = model.vectorDecoder(z_comp)

        # è®¡ç®—æŸå¤±
        loss, recon_loss = loss_fn(x_batch, x_recon, z_comp, log_det)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # å­¦ä¹ ç‡è°ƒæ•´
        if use_lr_scheduler:
            scheduler.step(loss)

        # è®°å½•å­¦ä¹ ç‡è°ƒæ•´ï¼ˆæ‰‹åŠ¨å®ç° verbose åŠŸèƒ½ï¼‰
        current_lr = optimizer.param_groups[0]["lr"]
        if (
            use_lr_scheduler
            and epoch > 0
            and current_lr != optimizer.param_groups[0].get("prev_lr", current_lr)
        ):
            lr_update_counter += 1
            logging.info(f"Epoch {epoch+1}: å­¦ä¹ ç‡è°ƒæ•´ä¸º {current_lr:.6f}")
        optimizer.param_groups[0]["prev_lr"] = current_lr

        # è®°å½•æŸå¤±
        train_loss_history.append(loss.item())
        train_recon_loss_history.append(recon_loss.item())

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if loss.item() < best_loss:
            best_loss = loss.item()
            torch.save(model.state_dict(), save_path)

        if (epoch + 1) % 50 == 0:
            logging.info(
                f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}, Recon Loss: {recon_loss.item():.6f}, LR: {current_lr:.6f}"
            )

    logging.info(f"\nè®­ç»ƒå®Œæˆï¼Œå­¦ä¹ ç‡å…±è°ƒæ•´äº† {lr_update_counter} æ¬¡")
    logging.info(f"æœ€ä½³æŸå¤±: {best_loss:.6f}")

    # åŠ è½½æœ€ä½³æ¨¡å‹ç”¨äºæµ‹è¯•
    logging.info("åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•...")
    model.load_state_dict(torch.load(save_path))

    logging.info("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿...")
    plot_loss_curves(
        train_loss_history,
        train_recon_loss_history,
        save_path="assets/loss_curves_res_GR"
        + str(input_dim // m_dim)
        + "Lr["
        + str(use_lr_scheduler)
        + "]n"
        + str(n_layers)
        + "h"
        + str(hidden_dim)
        + "ph"
        + str(aux_predictor_hidden)
        + "E"
        + str(epochs)
        + ".png",
    )

    # ==================== æµ‹è¯•é˜¶æ®µ ====================
    logging.info("\n" + "=" * 60)
    logging.info("ğŸ§ª å¼€å§‹æµ‹è¯•ï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰...")
    logging.info("=" * 60)

    # ä½¿ç”¨æ‰€æœ‰çœŸå®æµ‹è¯•å›¾åƒ
    test_data_device = test_data.to(device)

    # å‹ç¼©
    with torch.no_grad():
        z_comp, _, _ = model.vectorEncoder(test_data_device)

    logging.info(f"æµ‹è¯•æ•°æ®ç»´åº¦: {test_data_device.shape}")
    logging.info(f"å‹ç¼©åç»´åº¦: {z_comp.shape}")
    logging.info(f"å‹ç¼©ç‡: {z_comp.shape[1] / test_data_device.shape[1]:.3f}")

    # è§£å‹
    with torch.no_grad():
        x_recon = model.vectorDecoder(z_comp)

    # è¯„ä¼°
    mae = F.l1_loss(test_data_device, x_recon).item()
    mse = F.mse_loss(test_data_device, x_recon).item()
    psnr_val = psnr(test_data_device, x_recon).item()

    logging.info(f"\nğŸ“Š æ•´ä½“æµ‹è¯•ç»“æœ:")
    logging.info(f"  é‡å»º MAE: {mae:.6f}")
    logging.info(f"  é‡å»º MSE: {mse:.6f}")
    logging.info(f"  PSNR: {psnr_val:.2f} dB")

    # å¯è§†åŒ–å¯¹æ¯”
    logging.info("\nğŸ“¸ ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾ï¼ˆçœŸå®æ•°æ® vs é‡å»ºç»“æœï¼‰...")
    visualize_comparison(
        test_data_device[:4],  # åªå±•ç¤ºå‰4å¼ 
        x_recon[:4],
        titles=[
            f"Real Image {z_comp.shape[1] / test_data_device.shape[1]:.3f}",
            f"Reconstructed {z_comp.shape[1] / test_data_device.shape[1]:.3f}",
        ],
        num_samples=min(4, len(test_data_device)),
        save_path="assets/Example_res_GR_"
        + str(input_dim // m_dim)
        + "Lr["
        + str(use_lr_scheduler)
        + "]n"
        + str(n_layers)
        + "h"
        + str(hidden_dim)
        + "ph"
        + str(aux_predictor_hidden)
        + "E"
        + str(epochs)
        + ".png",
    )

    # è®¡ç®—æ¯å¼ å›¾åƒçš„è¯¦ç»†æŒ‡æ ‡
    logging.info("\nğŸ“ˆ æ¯å¼ æµ‹è¯•å›¾åƒçš„è¯¦ç»†æŒ‡æ ‡:")
    for i in range(min(5, len(test_data_device))):
        psnr_single = psnr(test_data_device[i], x_recon[i]).item()
        mae_single = F.l1_loss(test_data_device[i], x_recon[i]).item()
        mse_single = F.mse_loss(test_data_device[i], x_recon[i]).item()
        logging.info(
            f"  å›¾åƒ {i+1}: PSNR = {psnr_single:.2f} dB, MAE = {mae_single:.6f}, MSE = {mse_single:.6f}"
        )

    logging.info("\n" + "=" * 60)
    logging.info("âœ… æµ‹è¯•å®Œæˆï¼")
    logging.info(f"  è®­ç»ƒæ•°æ®: {len(train_data)} å¼ ç”Ÿæˆå›¾åƒ")
    logging.info(f"  æµ‹è¯•æ•°æ®: {len(test_data)} å¼ çœŸå®å›¾åƒ")
    logging.info(f"  å‹ç¼©æ•ˆæœ: {input_dim} ç»´ â†’ {m_dim} ç»´")
    logging.info(f"  æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
    logging.info("=" * 60)
